{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 10\n",
    "## Plotting Points data: 311 data ðŸ“² ðŸ“² ðŸ“² ðŸ“² \n",
    "\n",
    "c4sue NYU @avigailvantu\n",
    "\n",
    "Today we will continue to work with Pandas and Matplotlib. We will also create some maps using geopandas. Looking into 311 complaints from the past month and from the same period in 2019 we will compare, group and visualize the cityâ€™s trends. Along the way we will create a GeoDataFrame, this is a geographical format that is similar enough to a data frame but has an extra dimension of geographical attributes to it.  Think of the times where we loaded a CSV data into QGIS and needed to merge with a swapfile of assign column to a geographical unit.\n",
    "\n",
    "This week we will be doing something similar, only with that we will transform a csv (which we will read into a data frame) and then assign columns in the data to represent geometry. That would enable us to then visualize the data quite easily. Weâ€™ll some pretty simple, yet cool, ways to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment I downloaded the 311 data from the NYC Open Data platform. I wanted to look into how people in the city complaint patterns were in the past month. In order to get a relative understating I will compare the data from 2020 to the same dates last year. Comparing similar periods in between years is a common method in highlighting changes and trends.  Thinking about time series, many phenomenas are seasonal. Which is why comparing one month to the previous month (feb 2020 in our case) would be tricker. Having said that, even the same period in two separate years is likely to have some differences, but hopefully less. \n",
    "\n",
    "- Data 2020: March 13th 2020-April 13th 2020\n",
    "- Data 2019: March 13th 2019-April 13th 2019 \n",
    "\n",
    "Both datasets are in this repo, but you are welcome to download it yourself too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 311 data 1 for this year and one for last year: \n",
    "\n",
    "data20 = pd.read_csv('311_March_April2020.csv')\n",
    "\n",
    "#load 2019 data \n",
    "\n",
    "data19 = pd.read_csv('311_March-April2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data20.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data19.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('shape 2020',data20.shape)\n",
    "print ('shape 2019',data19.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the changes between 2019 and 2020 data in terms of quantities of non emargency complaints in NYC? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the columns in the data? \n",
    "print ('2020 columns:',data20.columns)\n",
    "print ('2019 columns:',data19.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 311 data for 2019 and 2020 data by agency: \n",
    "\n",
    "Let's look into the \"value_counts\" function. That would return the number of values for each value in the Agencey column. Meaning we will get a list of how many complaints were chanaled into each agency. \n",
    "\n",
    "Check out this URL for the agencies acronyms\n",
    "https://www1.nyc.gov/site/mocs/about/agencies-acronyms-initialisms.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data19['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data20['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are some of the differences in patterns we are seeing in which agencies the calls have been channeled to between 2019 and 2020?  Which agencies have been seeing less activity and which ones more? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we worked mainly with Pandas (also some pyplot, numpy and datetime). In addiition to all these pacakges Pyhton also has some pretty neat geographical features! Let's check out a few of them on our data: \n",
    "\n",
    "## From DataFrame to GeoDataFrame ðŸ§®\n",
    "\n",
    "GeoDataFrame is a data frame that includes one column with a \"special\" status. This column is the \"geometry\" column which enbales Python to refer to the data as geogpraphical. In many cases, like in our case, we will not have the \"geomtry\" column built-in in the data. Instead, we will usually have x any y or Latitue and Longtitude that we will tranform into the needed format. \n",
    "\n",
    "To go from DataFRame---> GeoDataFrame:\n",
    "- we would want to tell python which columns can be used as \"geometry\". \n",
    "\n",
    "Note that the Geometry columns looks like this\n",
    "\n",
    "\n",
    "- POINT (LON LAT) \n",
    "\n",
    "The point() format will be created using the GeoDataFrame function. We will only need to tell Python which columns in the data are each (lon, lat).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data into geo data frame: \n",
    "\n",
    "gdf20 = gpd.GeoDataFrame(\n",
    "    data20, geometry=gpd.points_from_xy(data20.Longitude, data20.Latitude))\n",
    "\n",
    "gdf19 = gpd.GeoDataFrame(\n",
    "    data19, geometry=gpd.points_from_xy(data19.Longitude, data19.Latitude))\n",
    "\n",
    "#note that here we tell Python that the column: \n",
    "#data20.Longitude is the longtitute and data20.Latitude is the latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out our GeoDataFrame--> note the \"geometry\" column was added (all the way to the right)\n",
    "gdf20.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can fianly visualize the data: \n",
    "\n",
    "First: plot all points for the layer, not I am setting the marker zise on 0.3 since there are so many of them!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all 2020 data:\n",
    "gdf20.plot( color='red',legend=True,figsize=(12, 12),markersize=0.3)\n",
    "plt.axis('off')\n",
    "plt.title('311 complaints March13th-April 13th 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all 2019 data: \n",
    "gdf19.plot( color='blue',legend=True,figsize=(12, 12),markersize=0.3)\n",
    "plt.axis('off')\n",
    "plt.title('311 complaints March13th-April 13th 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exmine one agency: \n",
    "### HPD (Housing Preservation & Development)\n",
    "\n",
    "In order to make better sense of what are people reporting less in these past weeks, we will take a closer look at the different agencies complaints. \n",
    "\n",
    "We will start with HPD: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only hpd\n",
    "\n",
    "hpd19 = gdf19.loc[gdf19['Agency']=='HPD']\n",
    "hpd20 = gdf20.loc[gdf20['Agency']=='HPD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot HPD data for both 2019 and 2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd19.plot( color='blue',legend=True,figsize=(12, 12), markersize=2)\n",
    "plt.axis('off')\n",
    "plt.title('311 HPD complaints March13th-April 13th 2019')\n",
    "hpd20.plot( color='red',legend=True,figsize=(12, 12),markersize=2)\n",
    "plt.axis('off')\n",
    "plt.title('311 HPD complaints March13th-April 13th 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Q: Which areas seem to see the most impact in terms of \"lost complaints\"? \n",
    " \n",
    "## Another way for us to look into the data is to sub-slice it again: \n",
    "\n",
    "Now dive into the complaint types in the HPD complaints. So we can learn what are the types of housing complaint we are seeing. that would also help us compare what were some of the changes b/t both periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot hpd by complaint type:\n",
    "\n",
    "#1. for 2019 \n",
    "ax = hpd19.plot(column='Complaint Type',legend=True,figsize=(12, 12), alpha = 0.6,markersize=2)\n",
    "#we can also visualize HPD complaints based on the complaint type: \n",
    "plt.title('311 HPD complaints March13th - April 13th 2019 by Complaint type')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#2. for 2020 \n",
    "ax = hpd20.plot(column='Complaint Type',legend=True,figsize=(12, 12),alpha = 0.6,markersize=2)\n",
    "#we can also visualize HPD complaints based on the complaint type: \n",
    "plt.title('311 HPD complaints March13th - April 13th 2020 by Complaint type')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What information can we take away from these two maps? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way to look into the complaint types: \n",
    "On top of visualizng the data we can also look into the number of complaints of each type. An easy way to do so is to use the Group.by command. This is a pretty timple command that has a lot of options (more about it on other classes!). \n",
    "\n",
    "The main thing to know about group.by right now is that group.by operates on a dataframe so that it basically does 3 main things: \n",
    "\n",
    "1. Split : take the data and splits it according to the grouping condition \n",
    "2. Apply: calculates what we want it to do: sum, means count etc\n",
    "3. Combine: it combines the data into new groups \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd19['Complaint Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we will count group by complaint type so that: Python will Split the data according to each type of complaint (hot water, windows etc). Then it will Apply, meaning it would count how many of each compliant type the data has. Finally, Python will Combine the new grouped data. So in our case that would be number of complaints per each complaint type. Note that by doing so, our data frame structure will changes completely so that each row will represent a complaint type, and the data in the cells will be the count of how many of them are there in our data.  All that in one line of code :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group.by hpd complaints \n",
    "\n",
    "#1. for 2019\n",
    "hpd19_count_type = hpd19.groupby(['Complaint Type']).count()\n",
    "#1. for 2020\n",
    "hpd20_count_type = hpd20.groupby(['Complaint Type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at out new data for 2019 \n",
    "hpd19_count_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and for 2020\n",
    "hpd20_count_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because the all columns look the same we will remove them and only keep the first one\n",
    "\n",
    "hpd19_count_type = hpd19_count_type['Unique Key']\n",
    "hpd20_count_type = hpd20_count_type['Unique Key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd19_count_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's see the most common HPD complaints for both March/April 2019 and 2020:\n",
    "\n",
    "# sort data \n",
    "\n",
    "hpd19_count_type = hpd19_count_type.sort_values()\n",
    "\n",
    "hpd20_count_type = hpd20_count_type.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 most common complaints in 2019 were: \n",
    "hpd19_count_type.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#5 most common complaints in 2020  were: \n",
    "hpd20_count_type.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We see that the 5 most common HPD complaints in 2019 and 2020 remained the same. But we are seeing a lot less of many of these types (e.g. more than half less Unsanitary conditions  in 2020 compared to 2019)\n",
    "\n",
    "## here are the top 5 for both years :\n",
    "1. Heat/hot water --> 14840 in 2020 and 17742 in 2019 \n",
    "2. Unsanitary conditions --> 2988 in 2020 and 6218\tin 2019 \n",
    "3. Paint/ Plaster --> 1499 in 2020 and 4661 in 2019 \n",
    "4. Plumbing --> 2427 in 2020 and 4065 in 2019\n",
    "5. Door/Window --> 1194 in 2020 and 3001 in 2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "\n",
    "Your turn: \n",
    "\n",
    "So far we worked on the HPD data. \n",
    "\n",
    "We will now divide into groups, when each group will look into another agency complaints: \n",
    "\n",
    "# Group 1: NYPD\n",
    "# Group 2: DOT \n",
    "# Group 3: DEP \n",
    "# Group 4: DSNY \n",
    "# Group 5: DOHMH \n",
    "\n",
    "For each groups: \n",
    "\n",
    "1. Please filter the subset of the data that has *YOUR* Agencey name\n",
    "2. Plot, summarize and group.by the data for both 2019 and 2020 \n",
    " \n",
    "Deliver:  \n",
    "- a. What are the patterns in *YOUR* agency complaints between the 2019 and 2020 data? \n",
    "- b. What are some geogrpaphical patterns you are seeing comparing both years?\n",
    "\n",
    "In class: present your main findings. For you homework: submit your jupyter notebook. In addition on your NYU classes submissions write a short summary of your findings. \n",
    "\n",
    "Due: April 27th 2020 before class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
